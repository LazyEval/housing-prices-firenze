{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import regex as re\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw = '/home/matteo@COPPET/Documents/data_science/projects/housing_prices_firenze/data/raw/'\n",
    "path_interim = '/home/matteo@COPPET/Documents/data_science/projects/housing_prices_firenze/data/interim/'\n",
    "immobiliare = 'https://www.immobiliare.it/vendita-case/firenze/'\n",
    "n_pages = 366\n",
    "average_price = 3.457 # Average price per square meter in Sept 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(path_raw+'urls.txt', 'w') as f:\n",
    "    urls = []\n",
    "    for i in range(1, n_pages+1):\n",
    "    \n",
    "        if i == 1:\n",
    "            url = immobiliare\n",
    "        else:\n",
    "            url = immobiliare + '?pag=' + str(i)\n",
    "    \n",
    "        response = get(url)\n",
    "        html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        a = html_soup.find_all(href=re.compile(\"/annunci/\"))\n",
    "        \n",
    "        for item in a:\n",
    "            href = item.get('href')\n",
    "            urls.append(href)\n",
    "            f.write(\"%s\\n\" % href)\n",
    "        print('Loop ' + str(i) + ' completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_raw+'urls.txt', 'r') as f:\n",
    "    urls = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all possible entry titles\n",
    "all_titles = [[], [], []]\n",
    "c = 0\n",
    "for url in urls:\n",
    "    response = get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "    tables = html_soup.find_all(class_=\"im-features__list\")\n",
    "    \n",
    "    for i, table in enumerate(tables[:3]):\n",
    "        titles = table.find_all(class_='im-features__title')\n",
    "        for title in titles:\n",
    "            if title.text not in all_titles[i]:\n",
    "                all_titles[i].append(title.text)\n",
    "    if c%500 == 0:\n",
    "        print('Loop ' + str(c) + ' completed.')\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write titles to file\n",
    "with open(path_raw+'titles.txt', 'w') as f:\n",
    "    for tables in all_titles:\n",
    "        for title in tables:\n",
    "            f.write(\"%s\\n\" % title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file into list of lists\n",
    "with open(path_raw+'titles.txt', 'r') as f:\n",
    "    all_titles = [[], [], []]\n",
    "    for i in range(3):\n",
    "        for j, line in enumerate(f):\n",
    "            if j<=14:\n",
    "                all_titles[0].append(line.strip())\n",
    "            elif j<=27:\n",
    "                all_titles[1].append(line.strip())\n",
    "            else:\n",
    "                all_titles[2].append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "caratteristiche = {key: list() for key in all_titles[0]}\n",
    "caratteristiche['indirizzo'] = []\n",
    "caratteristiche['zona'] = []\n",
    "\n",
    "costi = {key: list() for key in all_titles[1]}\n",
    "efficienza_energetica = {key: list() for key in all_titles[2]}\n",
    "\n",
    "dicts = [caratteristiche, costi, efficienza_energetica]\n",
    "\n",
    "loop = 0\n",
    "\n",
    "for url in urls:\n",
    "    try:\n",
    "        response = get(url)\n",
    "        html_soup = BeautifulSoup(response.text, 'lxml')\n",
    "        \n",
    "        # Get area\n",
    "        area = html_soup.find('div', class_=\"im-relatedLink__container\").find_all('a')\n",
    "        caratteristiche['zona'].append(area[-1]['href'][63:])\n",
    "        \n",
    "        # Get address\n",
    "        addresses = html_soup.find_all(class_=\"im-location\")\n",
    "        addresses_text = list(set([address.text for address in addresses]))\n",
    "        caratteristiche['indirizzo'].append(addresses_text)\n",
    "\n",
    "        # Get tables\n",
    "        tables = html_soup.find_all(class_=\"im-features__list\")\n",
    "\n",
    "        for i, table in enumerate(tables[:3]):\n",
    "\n",
    "            # Get entries (left) and values (right) for first 3 tables\n",
    "            titles = table.find_all(class_='im-features__title')\n",
    "            values = table.find_all(class_='im-features__value')\n",
    "            \n",
    "            titles_text = [title.text for title in titles]\n",
    "            values_text = [value.text.strip() for value in values]\n",
    "            entries = dict(zip(titles_text, values_text))\n",
    "            \n",
    "            c = 0\n",
    "            \n",
    "            for key in dicts[i].keys():\n",
    "                if key in titles_text:\n",
    "                    dicts[i][key].append(entries[key])\n",
    "                    c += 1\n",
    "                elif key not in ['indirizzo', 'zona']:\n",
    "                    dicts[i][key].append('n/a')\n",
    "        \n",
    "        print('Loop ' + str(loop) + ' completed.')\n",
    "        loop += 1\n",
    "    except:        \n",
    "        print('Loop ' + str(loop) + ' failed.')\n",
    "        loop += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caratteristiche = pd.DataFrame.from_dict(dicts[0], orient='index').transpose()\n",
    "costi = pd.DataFrame.from_dict(dicts[1], orient='index').transpose()\n",
    "efficienza_energetica = pd.DataFrame.from_dict(dicts[2], orient='index').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caratteristiche.to_excel(path_interim+'caratteristiche.xlsx', index=False)\n",
    "costi.to_excel(path_interim+'costi.xlsx', index=False)\n",
    "efficienza_energetica.to_excel(path_interim+'efficienza_energetica.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
