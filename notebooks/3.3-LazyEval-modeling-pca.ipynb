{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import estimators and transformers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from src.features import CustomEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Import predictors\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "path_processed = '/home/matteo@COPPET/Documents/data_science/projects/housing_prices_firenze/data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_processed+'data_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature selection and splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Prezzo_EUR'\n",
    "\n",
    "X = df.drop(columns=['Prezzo_per_m2']+[target])\n",
    "y = df[target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['Tipologia', 'Zona', 'Stato', 'Tipo_proprietà', 'Riscaldamento_A_C', 'Tipo_riscaldamento',\n",
    "                'Alimentazione_riscaldamento', 'Classe_energetica', 'Piano']\n",
    "num_features = ['Superficie_m2', 'Num_bagni', 'Num_tot_locali', 'Anno_costruzione']\n",
    "\n",
    "# cat_features = ['Tipologia', 'Zona', 'Tipo_proprietà', 'Tipo_riscaldamento', 'Classe_energetica']\n",
    "# num_features = ['Superficie_m2', 'Num_tot_locali']\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "    ('imputing', SimpleImputer(strategy='most_frequent')),\n",
    "    ('oh_encoding', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "num_transformer = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('imputing', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    ('categoricals', cat_transformer, cat_features),\n",
    "    ('numericals', num_transformer, num_features)\n",
    "],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 First model (benchmarking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 140714.30325511587\n",
      "Mean cross validation score: 145152.11194017527\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('pca', PCA(n_components=20)),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "\n",
    "# Train set score\n",
    "print('Training set score: {}'.format(mean_absolute_error(y_train, y_train_pred)))\n",
    "\n",
    "# Cross validation score\n",
    "scores = cross_val_score(pipe, X_train, y_train, scoring='neg_mean_absolute_error', cv=10)\n",
    "print('Mean cross validation score: {}'.format(np.mean(-scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 140608.05917375383\n",
      "Mean cross validation score: 145229.24037456853\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('pca', PCA(n_components=20)),\n",
    "    ('model', Ridge())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "\n",
    "# Train set score\n",
    "print('Training set score: {}'.format(mean_absolute_error(y_train, y_train_pred)))\n",
    "\n",
    "# Cross validation score\n",
    "scores = cross_val_score(pipe, X_train, y_train, scoring='neg_mean_absolute_error', cv=10)\n",
    "print('Mean cross validation score: {}'.format(np.mean(-scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 52457.00963679461\n",
      "Mean cross validation score: 127183.15819502738\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('pca', PCA(n_components=20)),\n",
    "    ('model', RandomForestRegressor(random_state=0))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "\n",
    "# Train set score\n",
    "print('Training set score: {}'.format(mean_absolute_error(y_train, y_train_pred)))\n",
    "\n",
    "# Cross validation score\n",
    "scores = cross_val_score(pipe, X_train, y_train, scoring='neg_mean_absolute_error', cv=10)\n",
    "print('Mean cross validation score: {}'.format(np.mean(-scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tuning PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138092.86333382674 {'pca__n_components': 5}\n",
      "127370.2117892134 {'pca__n_components': 10}\n",
      "126728.2960333098 {'pca__n_components': 20}\n",
      "126374.47363327583 {'pca__n_components': 30}\n",
      "127525.06746861087 {'pca__n_components': 40}\n",
      "127186.68925650857 {'pca__n_components': 50}\n",
      "126187.37486419182 {'pca__n_components': 60}\n",
      "127213.68811021633 {'pca__n_components': None}\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('pca', PCA()),\n",
    "    ('model', RandomForestRegressor(random_state=0))\n",
    "])\n",
    "\n",
    "param_grid = {'pca__n_components': [5, 10, 20, 30, 40, 50, 60, None]}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, verbose=0, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(-mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 47843.23735200023\n",
      "Mean cross validation score: 125536.28658040872\n"
     ]
    }
   ],
   "source": [
    "pipe = grid_search.best_estimator_\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "\n",
    "# Train set score\n",
    "print('Training set score: {}'.format(mean_absolute_error(y_train, y_train_pred)))\n",
    "\n",
    "# Cross validation score\n",
    "scores = cross_val_score(pipe, X_train, y_train, scoring='neg_mean_absolute_error', cv=10)\n",
    "print('Mean cross validation score: {}'.format(np.mean(-scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
